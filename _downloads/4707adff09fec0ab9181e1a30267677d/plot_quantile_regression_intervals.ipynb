{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Quantile regression forest prediction intervals\n\nAn example of how to use a quantile regression forest to plot prediction\nintervals on the California Housing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import FuncFormatter\nfrom sklearn import datasets\nfrom sklearn.model_selection import KFold\nfrom sklearn.utils.validation import check_random_state\n\nfrom quantile_forest import RandomForestQuantileRegressor\n\nrng = check_random_state(0)\n\n# Load the California Housing Prices dataset.\ncalifornia = datasets.fetch_california_housing()\nn_samples = min(california.target.size, 1000)\nperm = rng.permutation(n_samples)\nX = california.data[perm]\ny = california.target[perm]\n\nqrf = RandomForestQuantileRegressor(n_estimators=100, random_state=0)\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(X)\n\ny_true = []\ny_pred = []\ny_pred_low = []\ny_pred_upp = []\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test, y_train, y_test = (\n        X[train_index],\n        X[test_index],\n        y[train_index],\n        y[test_index],\n    )\n\n    qrf.set_params(max_features=X_train.shape[1] // 3)\n    qrf.fit(X_train, y_train)\n\n    # Get predictions at 95% prediction intervals and median.\n    y_pred_i = qrf.predict(X_test, quantiles=[0.025, 0.5, 0.975])\n\n    y_true = np.concatenate((y_true, y_test))\n    y_pred = np.concatenate((y_pred, y_pred_i[:, 1]))\n    y_pred_low = np.concatenate((y_pred_low, y_pred_i[:, 0]))\n    y_pred_upp = np.concatenate((y_pred_upp, y_pred_i[:, 2]))\n\n\ndef plot_calibration_and_intervals(y_true, y_pred, y_pred_low, y_pred_upp):\n    def plot_calibration(ax, y_true, y_pred_low, y_pred_upp, price_formatter):\n        y_min = min(np.minimum(y_true, y_pred))\n        y_max = max(np.maximum(y_true, y_pred))\n\n        for low, mid, upp in zip(y_pred_low, y_pred, y_pred_upp):\n            ax.plot([mid, mid], [low, upp], lw=4, c=\"#e0f2ff\")\n\n        ax.plot(y_pred, y_true, c=\"#f2a619\", lw=0, marker=\".\", ms=5)\n        ax.plot(y_pred, y_pred_low, alpha=0.4, c=\"#006aff\", lw=0, marker=\"_\", ms=4)\n        ax.plot(y_pred, y_pred_upp, alpha=0.4, c=\"#006aff\", lw=0, marker=\"_\", ms=4)\n        ax.plot([y_min, y_max], [y_min, y_max], ls=\"--\", lw=1, c=\"grey\")\n        ax.grid(axis=\"x\", color=\"0.95\")\n        ax.grid(axis=\"y\", color=\"0.95\")\n        ax.xaxis.set_major_formatter(price_formatter)\n        ax.yaxis.set_major_formatter(price_formatter)\n        ax.set_xlim(y_min, y_max)\n        ax.set_ylim(y_min, y_max)\n        ax.set_xlabel(\"Fitted Values (Conditional Median)\")\n        ax.set_ylabel(\"Observed Values\")\n\n    def plot_intervals(ax, y_true, y_pred_low, y_pred_upp, price_formatter):\n        # Center data, with the mean of the prediction interval at 0.\n        mean = (y_pred_low + y_pred_upp) / 2\n        y_true -= mean\n        y_pred_low -= mean\n        y_pred_upp -= mean\n\n        ax.plot(y_true, c=\"#f2a619\", lw=0, marker=\".\", ms=5)\n        ax.fill_between(\n            np.arange(len(y_pred_upp)),\n            y_pred_low,\n            y_pred_upp,\n            alpha=0.8,\n            color=\"#e0f2ff\",\n        )\n        ax.plot(np.arange(n_samples), y_pred_low, alpha=0.8, c=\"#006aff\", lw=2)\n        ax.plot(np.arange(n_samples), y_pred_upp, alpha=0.8, c=\"#006aff\", lw=2)\n        ax.grid(axis=\"x\", color=\"0.95\")\n        ax.grid(axis=\"y\", color=\"0.95\")\n        ax.yaxis.set_major_formatter(price_formatter)\n        ax.set_xlim([0, n_samples])\n        ax.set_xlabel(\"Ordered Samples\")\n        ax.set_ylabel(\"Observed Values and Prediction Intervals\")\n\n    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\n    usd_formatter = FuncFormatter(lambda x, p: f\"${format(int(x) * 100, ',')}k\")\n\n    y_pred_interval = y_pred_upp - y_pred_low\n    sort_idx = np.argsort(y_pred)\n    y_true = y_true[sort_idx]\n    y_pred = y_pred[sort_idx]\n    y_pred_low = y_pred_low[sort_idx]\n    y_pred_upp = y_pred_upp[sort_idx]\n\n    plot_calibration(ax1, y_true, y_pred_low, y_pred_upp, usd_formatter)\n\n    y_pred_interval = y_pred_upp - y_pred_low\n    sort_idx = np.argsort(y_pred_interval)\n    y_true = y_true[sort_idx]\n    y_pred_low = y_pred_low[sort_idx]\n    y_pred_upp = y_pred_upp[sort_idx]\n\n    plot_intervals(ax2, y_true, y_pred_low, y_pred_upp, usd_formatter)\n\n    plt.subplots_adjust(top=0.15)\n    fig.tight_layout(pad=3)\n\n    plt.show()\n\n\nplot_calibration_and_intervals(y_true, y_pred, y_pred_low, y_pred_upp)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}